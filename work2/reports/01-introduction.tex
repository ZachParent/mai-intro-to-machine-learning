\section{Introduction}
\label{sec:introduction}

Machine learning classification algorithms play a crucial role in modern data analysis, enabling automated decision-making across diverse domains from medical diagnostics to pattern recognition. This study focuses on evaluating and comparing two fundamental classification algorithms: k-Nearest Neighbors (KNN) and Support Vector Machines (SVM), along with instance reduction techniques to improve their efficiency.

\subsection{Background}

Classification algorithms assign predefined categories to data points based on their features. While many sophisticated classification methods exist, KNN and SVM remain widely used due to their interpretability and strong theoretical foundations. KNN operates by examining the closest training examples to make predictions, while SVM finds optimal hyperplanes to separate classes in feature space.

A key challenge with instance-based methods like KNN is their computational and storage requirements, 
particularly for large datasets. Instance reduction techniques address this limitation by identifying 
and preserving only the most informative training examples, potentially improving both efficiency 
and generalization~\cite{knn}.

\subsection{Research Objectives}

This study addresses three primary research questions:

\begin{enumerate}
    \item How do KNN and SVM compare in terms of classification accuracy and computational efficiency across datasets with different characteristics?
    \item What impact do various hyperparameters, such as distance metrics, weighting schemes, and kernel functions have on model performance?
    \item Can instance reduction techniques maintain classification accuracy while significantly reducing storage and computational requirements?
\end{enumerate}

\subsection{Methodology Overview}

We evaluate these questions using two carefully selected datasets:
\begin{itemize}
    \item The Mushroom dataset (8,124 instances) - featuring categorical attributes and balanced classes
    \item The Hepatitis dataset (155 instances) - containing mixed data types and imbalanced classes
\end{itemize}

Our analysis employs rigorous statistical testing to compare model configurations and reduction techniques. We use cross-validation and multiple performance metrics to ensure robust conclusions.
