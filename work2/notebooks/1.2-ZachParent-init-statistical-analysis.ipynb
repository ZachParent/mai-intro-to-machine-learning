{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import itertools\n",
    "import time\n",
    "from typing import List, Tuple, Dict\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score\n",
    "\n",
    "from tools.metrics import train_and_evaluate_model, cross_validate\n",
    "from tools.knn import KNNClassifier\n",
    "from tools.distance import (\n",
    "    ManhattanDistance,\n",
    "    EuclideanDistance,\n",
    "    ChebyshevDistance,\n",
    "    MahalanobisDistance,\n",
    ")\n",
    "from tools.voting import MajorityClassVote, InverseDistanceWeightedVote, ShepardsWorkVote\n",
    "from tools.preprocess import (\n",
    "    preprocess_hepatitis_datasets,\n",
    "    load_datasets,\n",
    "    preprocess_mushroom_datasets,\n",
    ")\n",
    "from tools.weighting import InformationGainWeighting, ReliefFWeighting, EqualWeighting\n",
    "from tools.reduction import GCNN, ENNTH, drop3, edited_nearest_neighbor\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC as SVMClassifier\n",
    "\n",
    "import logging\n",
    "\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"../data\"\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_svm(\n",
    "    train_dfs: List[pd.DataFrame],\n",
    "    test_dfs: List[pd.DataFrame],\n",
    "    dataset_name: str,\n",
    "    class_columns_per_ds: Dict[str, str],\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Run SVM classification with various parameter configurations.\n",
    "    \"\"\"\n",
    "    # SVM Parameters\n",
    "    c_values = [1, 3, 5, 7]\n",
    "    kernel_types = [\"linear\", \"poly\", \"rbf\", \"sigmoid\"]\n",
    "\n",
    "    # Results DF\n",
    "    results_svm = pd.DataFrame(\n",
    "        columns=[\n",
    "            \"C\",\n",
    "            \"kernel_type\",\n",
    "            \"accuracy\",\n",
    "            \"f1\",\n",
    "            \"TP\",\n",
    "            \"TN\",\n",
    "            \"FP\",\n",
    "            \"FN\",\n",
    "            \"train_time\",\n",
    "            \"test_time\",\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Run all parameter configurations\n",
    "    for C, kernel_type in itertools.product(c_values, kernel_types):\n",
    "        svm = SVMClassifier(\n",
    "            C=C,\n",
    "            kernel=kernel_type,\n",
    "        )\n",
    "\n",
    "        logging.debug(f\"Running SVM: [kernel={kernel_type}, C={C}]\")\n",
    "\n",
    "        y_trues_all, y_preds_all = [], []\n",
    "        total_train_time, total_test_time = 0.0, 0.0\n",
    "\n",
    "        # Cross-validate\n",
    "        for train_df, test_df in zip(train_dfs, test_dfs):\n",
    "            X_train = train_df.drop(columns=[class_columns_per_ds[dataset_name]])\n",
    "            y_train = train_df[class_columns_per_ds[dataset_name]]\n",
    "            X_test = test_df.drop(columns=[class_columns_per_ds[dataset_name]])\n",
    "            y_test = test_df[class_columns_per_ds[dataset_name]]\n",
    "\n",
    "            # Train and evaluate the SVM model\n",
    "            y_true, y_pred, train_time, test_time = train_and_evaluate_model(\n",
    "                svm, X_train, y_train, X_test, y_test\n",
    "            )\n",
    "\n",
    "            # Update totals\n",
    "            total_train_time += train_time\n",
    "            total_test_time += test_time\n",
    "\n",
    "            # Collect true labels and predictions\n",
    "            y_trues_all.extend(y_true)\n",
    "            y_preds_all.extend(y_pred)\n",
    "\n",
    "        # Compute confusion matrix and metrics\n",
    "        cm = confusion_matrix(y_trues_all, y_preds_all)\n",
    "        tn, fp, fn, tp = cm.ravel()\n",
    "        accuracy = accuracy_score(y_trues_all, y_preds_all)\n",
    "        f1 = f1_score(y_trues_all, y_preds_all)\n",
    "\n",
    "        # Append the results\n",
    "        results_svm.loc[len(results_svm)] = [\n",
    "            C,\n",
    "            kernel_type,\n",
    "            accuracy,\n",
    "            f1,\n",
    "            tp,\n",
    "            tn,\n",
    "            fp,\n",
    "            fn,\n",
    "            total_train_time,\n",
    "            total_test_time,\n",
    "        ]\n",
    "\n",
    "    # Save the results for SVM\n",
    "    file_path_svm = os.path.join(DATA_DIR, \"cross_validated_results\", f\"svm_{dataset_name}.csv\")\n",
    "    results_svm.to_csv(file_path_svm, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_knn(\n",
    "    train_dfs: List[pd.DataFrame],\n",
    "    test_dfs: List[pd.DataFrame],\n",
    "    dataset_name: str,\n",
    "    class_columns_per_ds: Dict[str, str],\n",
    "    full_data_X: pd.DataFrame,\n",
    "    full_data_y: pd.Series,\n",
    ") -> Tuple[KNNClassifier, Dict[str, np.ndarray]]:\n",
    "    \"\"\"\n",
    "    Run KNN classification with various parameter configurations.\n",
    "    \"\"\"\n",
    "    # Define CM for MahalanobisDistance\n",
    "    # TODO: fix this for MahalanobisDistance\n",
    "    # covariance_matrix = np.cov(train_dfs[0].drop(columns=[class_columns_per_ds[dataset_name]]).apply(pd.to_numeric, errors='coerce'),\n",
    "    #                         rowvar=False)\n",
    "\n",
    "    # KNN Parameters\n",
    "    k_values = [1, 3, 5, 7]\n",
    "    distance_funcs = [ManhattanDistance(), EuclideanDistance(), ChebyshevDistance()]\n",
    "    voting_funcs = [MajorityClassVote(), InverseDistanceWeightedVote(), ShepardsWorkVote()]\n",
    "    weighting_funcs = [EqualWeighting(), InformationGainWeighting(), ReliefFWeighting()]\n",
    "\n",
    "    # Results DF\n",
    "    results = pd.DataFrame(\n",
    "        columns=[\n",
    "            \"k\",\n",
    "            \"distance_func\",\n",
    "            \"voting_func\",\n",
    "            \"weighting_func\",\n",
    "            \"accuracy\",\n",
    "            \"f1\",\n",
    "            \"TP\",\n",
    "            \"TN\",\n",
    "            \"FP\",\n",
    "            \"FN\",\n",
    "            \"train_time\",\n",
    "            \"test_time\",\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    logging.info(\"Fitting weighting functions\")\n",
    "    weights = {}\n",
    "    for weighting_func in weighting_funcs:\n",
    "        weighting_func.fit(full_data_X, full_data_y)\n",
    "        weights[weighting_func.__class__.__name__] = weighting_func.get_weights()\n",
    "\n",
    "    # Run all parameter configurations\n",
    "    best_config_instance = None\n",
    "    for k, distance_func, voting_func, weighting_func in itertools.product(\n",
    "        k_values, distance_funcs, voting_funcs, weighting_funcs\n",
    "    ):\n",
    "\n",
    "        knn = KNNClassifier(\n",
    "            k=k,\n",
    "            distance_func=distance_func,\n",
    "            voting_func=voting_func,\n",
    "            weights=weights[weighting_func.__class__.__name__],\n",
    "        )\n",
    "\n",
    "        logging.debug(\n",
    "            f\"Running KNN: [weighting_func={weighting_func.__class__.__name__}, distance_func={distance_func.__class__.__name__}, voting_func={voting_func.__class__.__name__}, k={k}]\"\n",
    "        )\n",
    "\n",
    "        y_trues_all, y_preds_all, train_time, test_time = cross_validate(\n",
    "            knn, train_dfs, test_dfs, class_columns_per_ds[dataset_name]\n",
    "        )\n",
    "\n",
    "        # Compute confusion matrix and accuracy\n",
    "        cm = confusion_matrix(y_trues_all, y_preds_all)\n",
    "        tn, fp, fn, tp = cm.ravel()\n",
    "        accuracy = accuracy_score(y_trues_all, y_preds_all)\n",
    "        f1 = f1_score(y_trues_all, y_preds_all)\n",
    "        # Append the results\n",
    "        results.loc[len(results)] = [\n",
    "            k,\n",
    "            distance_func.__class__.__name__,\n",
    "            voting_func.__class__.__name__,\n",
    "            weighting_func.__class__.__name__,\n",
    "            accuracy,\n",
    "            f1,\n",
    "            tp,\n",
    "            tn,\n",
    "            fp,\n",
    "            fn,\n",
    "            train_time,\n",
    "            test_time,\n",
    "        ]\n",
    "\n",
    "        # Store best configuration instance\n",
    "        if best_config_instance is None or accuracy > results[\"accuracy\"].max():\n",
    "            best_config_instance = {\n",
    "                \"k\": k,\n",
    "                \"distance_func\": distance_func,  # Save the instance\n",
    "                \"voting_func\": voting_func,\n",
    "                \"weighting_func\": weighting_func,\n",
    "            }\n",
    "\n",
    "    # Save the results for KNN\n",
    "    file_path = os.path.join(DATA_DIR, \"cross_validated_results\", f\"knn_{dataset_name}.csv\")\n",
    "    results.to_csv(file_path, index=False)\n",
    "\n",
    "    return best_config_instance, weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_reduced_knn(\n",
    "    train_dfs: List[pd.DataFrame],\n",
    "    test_dfs: List[pd.DataFrame],\n",
    "    dataset_name: str,\n",
    "    class_columns_per_ds: Dict[str, str],\n",
    "    best_config_instance: Dict[str, any],\n",
    "    weights: Dict[str, np.ndarray],\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Run reduced KNN classification with various techniques.\n",
    "    \"\"\"\n",
    "    best_k = best_config_instance[\"k\"]\n",
    "    best_distance_func = best_config_instance[\"distance_func\"]\n",
    "    best_voting_func = best_config_instance[\"voting_func\"]\n",
    "    best_weighting_func = best_config_instance[\"weighting_func\"]\n",
    "\n",
    "    reduction_funcs = {\n",
    "        \"control\": lambda x, y, z, s: (x, y),\n",
    "        \"GGCN\": GCNN,\n",
    "        \"ENNTH\": ENNTH,\n",
    "        \"Drop3\": drop3,\n",
    "    }\n",
    "    reduction_results = pd.DataFrame(\n",
    "        columns=[\n",
    "            \"k\",\n",
    "            \"distance_func\",\n",
    "            \"voting_func\",\n",
    "            \"weighting_func\",\n",
    "            \"reduction_func\",\n",
    "            \"accuracy\",\n",
    "            \"f1\",\n",
    "            \"TP\",\n",
    "            \"TN\",\n",
    "            \"FP\",\n",
    "            \"FN\",\n",
    "            \"train_time\",\n",
    "            \"test_time\",\n",
    "            \"storage\",\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    best_k = 7\n",
    "    for reduction_func in reduction_funcs:\n",
    "        knn = KNNClassifier(\n",
    "            k=best_k,\n",
    "            distance_func=best_distance_func,  # Use instance, not string\n",
    "            voting_func=best_voting_func,\n",
    "            weights=weights[best_weighting_func.__class__.__name__],  # We will apply weights later\n",
    "        )\n",
    "\n",
    "        logging.debug(f\"Running KNN with reduction: {reduction_func}\")\n",
    "\n",
    "        y_trues_all, y_preds_all = [], []\n",
    "        total_train_time, total_test_time, total_storage = 0.0, 0.0, 0\n",
    "\n",
    "        for train_df, test_df in zip(train_dfs, test_dfs):\n",
    "            X_train = train_df.drop(columns=[class_columns_per_ds[dataset_name]])\n",
    "            y_train = train_df[class_columns_per_ds[dataset_name]]\n",
    "            X_test = test_df.drop(columns=[class_columns_per_ds[dataset_name]])\n",
    "            y_test = test_df[class_columns_per_ds[dataset_name]]\n",
    "\n",
    "            logging.debug(f\"Reducing training data with {reduction_func}\")\n",
    "            X_train_reduced, y_train_reduced = reduction_funcs[reduction_func](\n",
    "                X_train, y_train, best_k, knn\n",
    "            )\n",
    "\n",
    "            storage = len(X_train_reduced)\n",
    "\n",
    "            # Train and evaluate the KNN model\n",
    "            y_true, y_pred, train_time, test_time = train_and_evaluate_model(\n",
    "                knn, X_train_reduced, y_train_reduced, X_test, y_test\n",
    "            )\n",
    "            # Update totals\n",
    "            total_train_time += train_time\n",
    "            total_test_time += test_time\n",
    "            total_storage += storage\n",
    "            # Collect true labels and predictions\n",
    "            y_trues_all.extend(y_true)\n",
    "            y_preds_all.extend(y_pred)\n",
    "            logging.debug(\n",
    "                f\"Reduced training data storage: {len(X_train_reduced)} / {len(X_train)}. Took {train_time} seconds to train and {test_time} seconds to test.\"\n",
    "            )\n",
    "\n",
    "        # Compute confusion matrix and accuracy\n",
    "        cm = confusion_matrix(y_trues_all, y_preds_all)\n",
    "        tn, fp, fn, tp = cm.ravel()\n",
    "        accuracy = accuracy_score(y_trues_all, y_preds_all)\n",
    "        f1 = f1_score(y_trues_all, y_preds_all)\n",
    "\n",
    "        # Append the results\n",
    "        reduction_results.loc[len(reduction_results)] = [\n",
    "            best_k,\n",
    "            best_distance_func.__class__.__name__,\n",
    "            best_voting_func.__class__.__name__,\n",
    "            best_weighting_func.__class__.__name__,\n",
    "            reduction_func,\n",
    "            accuracy,\n",
    "            f1,\n",
    "            tp,\n",
    "            tn,\n",
    "            fp,\n",
    "            fn,\n",
    "            total_train_time,\n",
    "            total_test_time,\n",
    "            total_storage / 10,  # average storage over folds\n",
    "        ]\n",
    "\n",
    "    # Save the results for reduced KNN\n",
    "    file_path_reduction = os.path.join(\n",
    "        DATA_DIR, \"cross_validated_results\", f\"knn_reduction_{dataset_name}.csv\"\n",
    "    )\n",
    "    reduction_results.to_csv(file_path_reduction, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Running SVM...\n",
      "INFO:root:Running KNN...\n",
      "INFO:root:Fitting weighting functions\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 41\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# ========== KNN ==========\u001b[39;00m\n\u001b[1;32m     40\u001b[0m logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRunning KNN...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 41\u001b[0m best_config_instance, weights \u001b[38;5;241m=\u001b[39m \u001b[43mrun_knn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dfs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_dfs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclass_columns_per_ds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfull_data_X\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfull_data_y\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# ========== Reduced KNN ==========\u001b[39;00m\n\u001b[1;32m     47\u001b[0m logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRunning reduced KNN...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[4], line 64\u001b[0m, in \u001b[0;36mrun_knn\u001b[0;34m(train_dfs, test_dfs, dataset_name, class_columns_per_ds, full_data_X, full_data_y)\u001b[0m\n\u001b[1;32m     53\u001b[0m knn \u001b[38;5;241m=\u001b[39m KNNClassifier(\n\u001b[1;32m     54\u001b[0m     k\u001b[38;5;241m=\u001b[39mk,\n\u001b[1;32m     55\u001b[0m     distance_func\u001b[38;5;241m=\u001b[39mdistance_func,\n\u001b[1;32m     56\u001b[0m     voting_func\u001b[38;5;241m=\u001b[39mvoting_func,\n\u001b[1;32m     57\u001b[0m     weights\u001b[38;5;241m=\u001b[39mweights[weighting_func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m],\n\u001b[1;32m     58\u001b[0m )\n\u001b[1;32m     60\u001b[0m logging\u001b[38;5;241m.\u001b[39mdebug(\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRunning KNN: [weighting_func=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mweighting_func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, distance_func=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdistance_func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, voting_func=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvoting_func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, k=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     62\u001b[0m )\n\u001b[0;32m---> 64\u001b[0m y_trues_all, y_preds_all, train_time, test_time \u001b[38;5;241m=\u001b[39m \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m    \u001b[49m\u001b[43mknn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dfs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_dfs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclass_columns_per_ds\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdataset_name\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;66;03m# Compute confusion matrix and accuracy\u001b[39;00m\n\u001b[1;32m     69\u001b[0m cm \u001b[38;5;241m=\u001b[39m confusion_matrix(y_trues_all, y_preds_all)\n",
      "File \u001b[0;32m~/src/MAI/iml/work2/tools/metrics.py:83\u001b[0m, in \u001b[0;36mcross_validate\u001b[0;34m(estimator, train_dfs, test_dfs, target_col, use_proba, return_times, score_func)\u001b[0m\n\u001b[1;32m     80\u001b[0m X_test \u001b[38;5;241m=\u001b[39m test_df\u001b[38;5;241m.\u001b[39mdrop(target_col, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     81\u001b[0m y_test \u001b[38;5;241m=\u001b[39m test_df[target_col]\n\u001b[0;32m---> 83\u001b[0m y_true, y_pred, train_time, test_time \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_and_evaluate_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     84\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_proba\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     86\u001b[0m actuals_list\u001b[38;5;241m.\u001b[39mappend(y_true)\n\u001b[1;32m     87\u001b[0m preds_list\u001b[38;5;241m.\u001b[39mappend(y_pred)\n",
      "File \u001b[0;32m~/src/MAI/iml/work2/tools/metrics.py:46\u001b[0m, in \u001b[0;36mtrain_and_evaluate_model\u001b[0;34m(model, X_train, y_train, X_test, y_test, use_proba)\u001b[0m\n\u001b[1;32m     44\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict_proba(X_test)\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 46\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m test_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y_test, y_pred, train_time, test_time\n",
      "File \u001b[0;32m~/src/MAI/iml/work2/tools/knn.py:60\u001b[0m, in \u001b[0;36mKNNClassifier.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     58\u001b[0m predictions \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray(X):\n\u001b[0;32m---> 60\u001b[0m     distances \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     61\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistance_func(x_train, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights \u001b[38;5;241m*\u001b[39m x)\n\u001b[1;32m     62\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m x_train \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX_train\n\u001b[1;32m     63\u001b[0m     ]\n\u001b[1;32m     64\u001b[0m     distances_and_classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(distances, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my_train))\n\u001b[1;32m     65\u001b[0m     sorted_distances_and_classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(\n\u001b[1;32m     66\u001b[0m         distances_and_classes, key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m dis_and_cls: dis_and_cls[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     67\u001b[0m     )\n",
      "File \u001b[0;32m~/src/MAI/iml/work2/tools/knn.py:61\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     58\u001b[0m predictions \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray(X):\n\u001b[1;32m     60\u001b[0m     distances \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m---> 61\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistance_func(x_train, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweights\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m)\n\u001b[1;32m     62\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m x_train \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX_train\n\u001b[1;32m     63\u001b[0m     ]\n\u001b[1;32m     64\u001b[0m     distances_and_classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(distances, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my_train))\n\u001b[1;32m     65\u001b[0m     sorted_distances_and_classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(\n\u001b[1;32m     66\u001b[0m         distances_and_classes, key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m dis_and_cls: dis_and_cls[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     67\u001b[0m     )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Configurations\n",
    "dataset_name = \"hepatitis\"\n",
    "sample = 1000\n",
    "\n",
    "processing_funcs_per_ds = {\n",
    "    \"hepatitis\": preprocess_hepatitis_datasets,\n",
    "    \"mushroom\": preprocess_mushroom_datasets,\n",
    "}\n",
    "class_columns_per_ds = {\"hepatitis\": \"Class\", \"mushroom\": \"class\"}\n",
    "\n",
    "logging.debug(f\"Using {dataset_name} dataset...\")\n",
    "train_path = f\"{DATA_DIR}/raw/{dataset_name}/*train.arff\"\n",
    "test_path = f\"{DATA_DIR}/raw/{dataset_name}/*test.arff\"\n",
    "train_dfs = load_datasets(train_path)\n",
    "test_dfs = load_datasets(test_path)\n",
    "\n",
    "\n",
    "train_dfs = [df.head(sample) for df in train_dfs]\n",
    "test_dfs = [df.head(sample) for df in test_dfs]\n",
    "\n",
    "logging.debug(f\"train_path: {train_path}\")\n",
    "train_dfs = [processing_funcs_per_ds[dataset_name](df) for df in train_dfs]\n",
    "test_dfs = [processing_funcs_per_ds[dataset_name](df) for df in test_dfs]\n",
    "logging.debug(f\"Train datasets count: {len(train_dfs)}\")\n",
    "logging.debug(f\"Test datasets count: {len(test_dfs)}\")\n",
    "\n",
    "full_data = pd.concat([train_dfs[0], test_dfs[0]])\n",
    "full_data_X = full_data.drop(columns=[class_columns_per_ds[dataset_name]])\n",
    "full_data_y = full_data[class_columns_per_ds[dataset_name]]\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# ========== SVM ==========\n",
    "\n",
    "logging.info(\"Running SVM...\")\n",
    "run_svm(train_dfs, test_dfs, dataset_name, class_columns_per_ds)\n",
    "\n",
    "# ========== KNN ==========\n",
    "\n",
    "logging.info(\"Running KNN...\")\n",
    "best_config_instance, weights = run_knn(\n",
    "    train_dfs, test_dfs, dataset_name, class_columns_per_ds, full_data_X, full_data_y\n",
    ")\n",
    "\n",
    "# ========== Reduced KNN ==========\n",
    "\n",
    "logging.info(\"Running reduced KNN...\")\n",
    "run_reduced_knn(\n",
    "    train_dfs, test_dfs, dataset_name, class_columns_per_ds, best_config_instance, weights\n",
    ")\n",
    "\n",
    "logging.info(f\"Finished in {time.time() - start_time} seconds\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv-iml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
