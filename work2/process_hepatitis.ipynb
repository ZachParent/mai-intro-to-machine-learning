{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Processing\n",
    "\n",
    "Notebook file that loads the datasets and pre-processes the rows of each dataset accordingly.\n",
    "\n",
    "- Author: Kacper Poniatowski\n",
    "- Date: 07/10/2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import matplotlib\n",
    "import sklearn\n",
    "import seaborn\n",
    "from scipy.io import arff\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions relating to loading and pre-processing data\n",
    "\n",
    "# Function to return full project path\n",
    "def get_full_path():\n",
    "    return os.getcwd()\n",
    "\n",
    "# Function to load ARFF files and return a pandas DataFrame\n",
    "def load_arff_file(file_path):\n",
    "    data, meta = arff.loadarff(file_path)\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# Function to load all ARFF files in a directory\n",
    "def load_all_arff_files(directory):\n",
    "    all_data = [] \n",
    "    \n",
    "    # Loop through all files in the directory\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".arff\"): \n",
    "            file_path = os.path.join(directory, filename)\n",
    "\n",
    "            df = load_arff_file(file_path)\n",
    "\n",
    "            # Add the resulting df to the list\n",
    "            all_data.append(df) \n",
    "    \n",
    "    return all_data\n",
    "\n",
    "# Function to combine all of the arff files that are part of a dataset\n",
    "def combine_arff_files(dataset):\n",
    "    return pd.concat(dataset, ignore_index=True)\n",
    "\n",
    "# Function to compute the percentage of rows with missing values\n",
    "def percentage_missing_values(df):\n",
    "    total_rows = len(df)\n",
    "\n",
    "    # Rows with any missing values (returns a boolean Series)\n",
    "    missing_rows_mask = df.isnull().any(axis=1)\n",
    "\n",
    "    print(\"Rows with missing / empty / values:\")\n",
    "    print(f\"\\n{total_rows}\")\n",
    "    \n",
    "    # Number of rows with missing values\n",
    "    missing_rows_count = missing_rows_mask.sum()\n",
    "\n",
    "    # TODO: Return a txt file containing all of the rows which have missing rows.\n",
    "    # Inspect manually what is missing, and decide upon whether to remove the rows or \n",
    "    # add data (e.g.: median for that column).\n",
    "\n",
    "    # If adding values via median, need to calculate the median values for each column\n",
    "    # Perhaps in a new function, called at the beginning of this function.\n",
    "\n",
    "    # Also need to decide upon a normalisation strategy, and conversion of data to 1 type (continuous or categorical)\n",
    "    # I need to see what sort of data it is but I'm assuming it'll be continuous.\n",
    "    # If so, need to investigate what normalisation technique is ideal for continuous data.\n",
    "    # Also need to keep note in this notebook what exactly is being performed on the data (conversions, normalisations, etc...)\n",
    "    \n",
    "    return (missing_rows_count / total_rows) * 100 # Convert to percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "\n",
    "PROJECT_PATH = get_full_path()\n",
    "HEPATITIS_DATASET_DIR = f\"{PROJECT_PATH}\\\\datasetsCBR\\\\hepatitis\"\n",
    "MUSHROOM_DATASET_DIR = f\"{PROJECT_PATH}\\\\datasetsCBR\\\\mushroom\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1550\n",
      "Rows with missing / empty / values:\n",
      "\n",
      "1550\n",
      "81240\n",
      "Rows with missing / empty / values:\n",
      "\n",
      "81240\n"
     ]
    }
   ],
   "source": [
    "# Loading the data\n",
    "\n",
    "# Load all of the arff files associated with a dataset\n",
    "arff_files_data_hepa = load_all_arff_files(HEPATITIS_DATASET_DIR)\n",
    "arff_files_data_mush = load_all_arff_files(MUSHROOM_DATASET_DIR)\n",
    "\n",
    "# Combine all of the arff files into 1 dataset\n",
    "combined_dataset_hepa = combine_arff_files(arff_files_data_hepa)\n",
    "combined_dataset_mush = combine_arff_files(arff_files_data_mush)\n",
    "\n",
    "# Calculate the percentage of rows with missing values\n",
    "missing_values_hepa = percentage_missing_values(combined_dataset_hepa)\n",
    "missing_values_mush = percentage_missing_values(combined_dataset_mush)\n",
    "\n",
    "#print(f\"Percentage of rows that have missing values in 'hepatitis' dataset: {missing_values_hepa}\")\n",
    "#print(f\"Percentage of rows that have missing values in 'mushroom' dataset: {missing_values_mush}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
