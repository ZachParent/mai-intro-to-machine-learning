{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "import glob\n",
    "from itertools import product\n",
    "import pandas as pd\n",
    "import logging\n",
    "import os\n",
    "import pathlib\n",
    "from sklearn.base import BaseEstimator, ClusterMixin\n",
    "\n",
    "# Set up logger\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCRIPT_DIR = pathlib.Path(os.getcwd()).absolute()\n",
    "DATA_DIR = os.path.join(SCRIPT_DIR.parent, \"data\")\n",
    "PREPROCESSED_DATA_DIR = f'{DATA_DIR}/1_preprocessed/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "FuzzyCMeansParamsGrid = {\n",
    "    \"n_clusters\": [2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "    \"fuzzyness\": [1.5, 2, 2.5, 3, 3.5, 4, 4.5, 5],\n",
    "    \"suppression_factor\": [0.1, 0.2, 0.3, 0.4, 0.5]\n",
    "}\n",
    "\n",
    "FuzzyCMeansParamsGrid = {\n",
    "    \"n_clusters\": [2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "    \"fuzzyness\": [1.5, 2, 2.5, 3, 3.5, 4, 4.5, 5],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FuzzyCMeans(ClusterMixin, BaseEstimator):\n",
    "    def __init__(self, n_clusters: int, fuzzyness: float, suppression_rule='theta', suppression_param=0.5):\n",
    "        self.n_clusters = n_clusters\n",
    "        self.fuzzyness = fuzzyness\n",
    "        self.suppression_rule = suppression_rule  # 'theta', 'rho', 'beta', 'kappa', 'tau', 'sigma', 'xi'\n",
    "        self.suppression_param = suppression_param\n",
    "\n",
    "    def fit(self, X):\n",
    "        X = X.to_numpy()\n",
    "        n_samples, n_features = X.shape\n",
    "\n",
    "        print(n_samples, n_features)\n",
    "        \n",
    "        # Initialize cluster prototypes (randomly for this example)\n",
    "        print(np.random.choice(n_samples, self.n_clusters, replace=False))\n",
    "        self.cluster_prototypes_ = X[np.random.choice(n_samples, self.n_clusters, replace=False)]\n",
    "        print(self.cluster_prototypes_)\n",
    "\n",
    "        # Initialize fuzzy membership matrix\n",
    "        U = self._initialize_membership(X)\n",
    "\n",
    "        # Main loop (alternating optimization)\n",
    "        while True:\n",
    "            previous_prototypes = np.copy(self.cluster_prototypes_)\n",
    "\n",
    "            # 4. Compute distances\n",
    "            distances = self._compute_distances(X)\n",
    "\n",
    "            # 5. Update fuzzy membership matrix\n",
    "            U = self._update_membership(distances)\n",
    "\n",
    "            # 6. Apply suppression (context-sensitive)\n",
    "            U = self._apply_suppression(U, distances)\n",
    "\n",
    "            # 7. Update cluster prototypes\n",
    "            self.cluster_prototypes_ = self._update_prototypes(X, U)\n",
    "\n",
    "            # 8. Check for convergence\n",
    "            if np.linalg.norm(self.cluster_prototypes_ - previous_prototypes) < 1e-4:\n",
    "                break\n",
    "\n",
    "        # Assign labels (hard clustering)\n",
    "        self.labels_ = np.argmax(U, axis=1)\n",
    "        self.is_fitted_ = True\n",
    "        \n",
    "        return self\n",
    "\n",
    "    def _initialize_membership(self, X):\n",
    "        print('initialize membership')\n",
    "        U = np.random.rand(len(X), self.n_clusters)\n",
    "        U = U / np.sum(U, axis=1, keepdims=True)  # Normalize to satisfy probabilistic constraint\n",
    "        return U\n",
    "\n",
    "    def _compute_distances(self, X):\n",
    "        print('compute distances')\n",
    "        distances = np.zeros((len(X), self.n_clusters))\n",
    "        for i in range(self.n_clusters):\n",
    "            # print(self.cluster_prototypes_)\n",
    "            distances[:, i] = np.linalg.norm(X - self.cluster_prototypes_[i], axis=1)\n",
    "        return distances\n",
    "\n",
    "    def _update_membership(self, distances):\n",
    "        print('update membership')\n",
    "        m = self.fuzzyness\n",
    "        U = np.power(distances, -2 / (m - 1))\n",
    "        U = U / np.sum(U, axis=1, keepdims=True)  # Normalize\n",
    "        return U\n",
    "\n",
    "    def _apply_suppression(self, U, distances):\n",
    "        print('apply suppression')\n",
    "        suppressed_U = np.zeros_like(U)\n",
    "        winner_indices = np.argmax(U, axis=1)\n",
    "\n",
    "        for k in range(len(U)):\n",
    "            w = winner_indices[k]  # Winner cluster index\n",
    "            alpha_k = self._compute_suppression_rate(U[k, w], distances[k], w)\n",
    "\n",
    "            suppressed_U[k, :] = alpha_k * U[k, :]\n",
    "            suppressed_U[k, w] = 1 - alpha_k + alpha_k * U[k, w]\n",
    "\n",
    "        return suppressed_U\n",
    "\n",
    "    def _compute_suppression_rate(self, u_w, distances_k, w):\n",
    "        print('compute suppression rate')\n",
    "        m = self.fuzzyness\n",
    "        rule = self.suppression_rule\n",
    "        param = self.suppression_param\n",
    "\n",
    "        if rule == 'theta':\n",
    "            return 1 / (1 - u_w + u_w * (1 - param) ** (2 / (1 - m)))\n",
    "        elif rule == 'rho':\n",
    "            return 1 / (1 - u_w + param ** (2 / (1 - m)) * u_w ** ((3 - m) / (1 - m)))\n",
    "        elif rule == 'beta':\n",
    "            return 1 / (1 + u_w * (u_w ** (2 * param / (1 - m) / (1 - param)) - 1))\n",
    "        elif rule == 'kappa':\n",
    "            return 1 / (1 - u_w + u_w * (0.5 - (2 * param - 1) / 2 * np.sin(np.pi * u_w)) ** (2 / (1 - m)))\n",
    "        elif rule == 'tau':\n",
    "            return (1 - param) / (1 + u_w * param)\n",
    "        elif rule == 'sigma':\n",
    "            return (1 - u_w ** param) / (1 - u_w)\n",
    "        elif rule == 'xi':\n",
    "            return (1 - (np.sin(np.pi * u_w / 2)) ** param) / (1 - u_w)\n",
    "        else:\n",
    "            raise ValueError(\"Invalid suppression rule\")\n",
    "\n",
    "    def _update_prototypes(self, X, U):\n",
    "        print('update prototypes')\n",
    "        m = self.fuzzyness\n",
    "        U_m = np.power(U, m)\n",
    "        new_prototypes = np.dot(U_m.T, X) / np.sum(U_m, axis=0, keepdims=True).T\n",
    "        return new_prototypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 3)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = f\"{DATA_DIR}/1_preprocessed/synthetic.csv\"\n",
    "preprocessed_data  = pd.read_csv(data_path)\n",
    "preprocessed_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.857566</td>\n",
       "      <td>0.550049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.759748</td>\n",
       "      <td>0.491028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.280519</td>\n",
       "      <td>0.008275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.869937</td>\n",
       "      <td>0.566440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.667429</td>\n",
       "      <td>0.633430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>0.357380</td>\n",
       "      <td>0.810404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>0.763751</td>\n",
       "      <td>0.554461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>0.099039</td>\n",
       "      <td>0.749420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>0.843335</td>\n",
       "      <td>0.599050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>0.185473</td>\n",
       "      <td>0.781746</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1\n",
       "0    0.857566  0.550049\n",
       "1    0.759748  0.491028\n",
       "2    0.280519  0.008275\n",
       "3    0.869937  0.566440\n",
       "4    0.667429  0.633430\n",
       "..        ...       ...\n",
       "995  0.357380  0.810404\n",
       "996  0.763751  0.554461\n",
       "997  0.099039  0.749420\n",
       "998  0.843335  0.599050\n",
       "999  0.185473  0.781746\n",
       "\n",
       "[1000 rows x 2 columns]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "features_data = preprocessed_data.iloc[:, :-1]\n",
    "features_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_clusters': 2, 'fuzzyness': 1.5}\n",
      "1000 2\n",
      "[617 309]\n",
      "[[0.78484479 0.55197796]\n",
      " [0.40815904 0.84962758]]\n",
      "initialize membership\n",
      "compute distances\n",
      "[[0.78484479 0.55197796]\n",
      " [0.40815904 0.84962758]]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'iloc'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[135], line 8\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(param_dict)\n\u001b[1;32m      5\u001b[0m model \u001b[38;5;241m=\u001b[39m FuzzyCMeans(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparam_dict)\n\u001b[0;32m----> 8\u001b[0m clusters \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(clusters\u001b[38;5;241m.\u001b[39mlabels_)\n\u001b[1;32m     12\u001b[0m clustered_data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat(\n\u001b[1;32m     13\u001b[0m     [preprocessed_data\u001b[38;5;241m.\u001b[39miloc[:, :\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], pd\u001b[38;5;241m.\u001b[39mSeries(clusters, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcluster\u001b[39m\u001b[38;5;124m\"\u001b[39m)], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     14\u001b[0m )\n",
      "Cell \u001b[0;32mIn[131], line 27\u001b[0m, in \u001b[0;36mFuzzyCMeans.fit\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     24\u001b[0m previous_prototypes \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mcopy(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcluster_prototypes_)\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# 4. Compute distances\u001b[39;00m\n\u001b[0;32m---> 27\u001b[0m distances \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_compute_distances\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# 5. Update fuzzy membership matrix\u001b[39;00m\n\u001b[1;32m     30\u001b[0m U \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_membership(distances)\n",
      "Cell \u001b[0;32mIn[131], line 59\u001b[0m, in \u001b[0;36mFuzzyCMeans._compute_distances\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_clusters):\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcluster_prototypes_)\n\u001b[0;32m---> 59\u001b[0m     distances[:, i] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mnorm(X \u001b[38;5;241m-\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcluster_prototypes_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m[i,:], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m distances\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'iloc'"
     ]
    }
   ],
   "source": [
    "params_grid = FuzzyCMeansParamsGrid\n",
    "for params in product(*params_grid.values()): \n",
    "    param_dict = dict(zip(params_grid.keys(), params))\n",
    "    print(param_dict)\n",
    "    model = FuzzyCMeans(**param_dict)\n",
    "\n",
    "\n",
    "    clusters = model.fit(features_data)\n",
    "\n",
    "    print(clusters.labels_)\n",
    "\n",
    "    clustered_data = pd.concat(\n",
    "        [preprocessed_data.iloc[:, :-1], pd.Series(clusters, name=\"cluster\")], axis=1\n",
    "    )\n",
    "\n",
    "    # clustered_data_path = clustered_data_dir / f\"{','.join(f'{k}={v}' for k, v in param_dict.items())}.csv\"\n",
    "    # clustered_data.to_csv(clustered_data_path, index=False)\n",
    "    clustered_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
