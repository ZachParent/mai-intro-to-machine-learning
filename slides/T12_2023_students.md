# [[T12_2023_students.pdf#page=1&selection=10,0,12,16|BIAS AND FAIRNESS IN MACHINE LEARNING]]

[[bias]] and [[fairness]]
## [[T12_2023_students.pdf#page=6&selection=0,0,4,4|DEFINITION OF BIAS]]
> inclination or prejudice for or **against one person or group**, especially in a way considered to be unfair

## [[T12_2023_students.pdf#page=7&selection=0,0,4,8|DEFINITION OF FAIRNESS]]
> *impartial and just treatment* or behavior without favoritism or discrimination

in the context of machine learning

> An algorithm is fair if it makes predictions that do not favor or discriminate against certain individuals or groups based on sensitive characteristics

https://www.nytimes.com/2015/07/10/upshot/when-algorithms-discriminate.htm
> There is a widespread belief that software and algorithms that rely on data are objective
> 
> But software is not free of human influence. Algorithms are written and maintained by people, and machine learning algorithms adjust what they do based on people’s behavior. As a result … algorithms can reinforce human prejudices

## Examples of Bias
### [[T12_2023_students.pdf#page=14&selection=0,0,6,6|EXAMPLES OF BIAS IN COMPUTER VISION]]
![[T12_2023_students.pdf#page=14&rect=52,44,951,385]]
### [[T12_2023_students.pdf#page=15&selection=0,0,2,14|EXAMPLES OF BIAS IN NLP]]
![[T12_2023_students.pdf#page=15&rect=24,18,955,424]]